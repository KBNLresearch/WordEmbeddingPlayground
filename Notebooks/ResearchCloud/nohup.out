Processing zip files
{'/home/kaspar/ResearchDrive/1850-1859.zip', '/home/kaspar/ResearchDrive/1860-1869.zip', '/home/kaspar/ResearchDrive/1870-1879.zip', '/home/kaspar/ResearchDrive/1880-1889.zip'}
588784
728315
Traceback (most recent call last):
  File "train_word2vec_azure.py", line 21, in <module>
    sentences.prepareLines()
  File "/home/kaspar/KB-RiR/Notebooks/ResearchCloud/utils_parallel.py", line 135, in prepareLines
    out_file.write(s + "\n")
OSError: [Errno 28] No space left on device
Processing zip files
Traceback (most recent call last):
  File "train_word2vec_azure.py", line 21, in <module>
    sentences.prepareLines()
  File "/home/kaspar/KB-RiR/Notebooks/ResearchCloud/utils_parallel.py", line 133, in prepareLines
    with open(out_sents,'w') as out_file:
PermissionError: [Errno 13] Permission denied: '/mnt/1850-1890.txt'
Processing zip files
Traceback (most recent call last):
  File "train_word2vec_azure.py", line 21, in <module>
    sentences.prepareLines()
  File "/home/kaspar/KB-RiR/Notebooks/ResearchCloud/utils_parallel.py", line 133, in prepareLines
    with open(out_sents,'w') as out_file:
PermissionError: [Errno 13] Permission denied: '/data/1850-1890.txt'
Processing zip files
Traceback (most recent call last):
  File "train_word2vec_azure.py", line 21, in <module>
    sentences.prepareLines()
  File "/home/kaspar/KB-RiR/Notebooks/ResearchCloud/utils_parallel.py", line 133, in prepareLines
    with open(out_sents,'w') as out_file:
PermissionError: [Errno 13] Permission denied: '/data/1850-1890.txt'
Traceback (most recent call last):
  File "train_word2vec_azure.py", line 3, in <module>
    from utils_parallel import *
  File "/home/kaspar/KB-RiR/Notebooks/ResearchCloud/utils_parallel.py", line 1, in <module>
    from lxml import etree
ModuleNotFoundError: No module named 'lxml'
2019-11-25 18:15:17,938 : INFO : collecting all words and their counts
2019-11-25 18:15:17,938 : INFO : collected 0 word types from a corpus of 0 raw words and 0 sentences
2019-11-25 18:15:17,938 : INFO : Loading a fresh vocabulary
2019-11-25 18:15:17,938 : INFO : effective_min_count=10 retains 0 unique words (0% of original 0, drops 0)
2019-11-25 18:15:17,938 : INFO : effective_min_count=10 leaves 0 word corpus (0% of original 0, drops 0)
2019-11-25 18:15:17,938 : INFO : deleting the raw counts dictionary of 0 items
2019-11-25 18:15:17,938 : INFO : sample=0.001 downsamples 0 most-common words
2019-11-25 18:15:17,938 : INFO : downsampling leaves estimated 0 word corpus (0.0% of prior 0)
2019-11-25 18:15:17,938 : INFO : estimated required memory for 0 words and 300 dimensions: 0 bytes
2019-11-25 18:15:17,938 : INFO : resetting layer weights
Zip files processed and stored in /data/1850-1890.txt
0
Traceback (most recent call last):
  File "train_word2vec_azure.py", line 28, in <module>
    model.train(sentences=sentences, total_examples=total_examples, epochs=EPOCH)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/gensim/models/word2vec.py", line 910, in train
    queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/gensim/models/base_any2vec.py", line 1081, in train
    **kwargs)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/gensim/models/base_any2vec.py", line 536, in train
    total_words=total_words, **kwargs)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/gensim/models/base_any2vec.py", line 1187, in _check_training_sanity
    raise RuntimeError("you must first build vocabulary before training the model")
RuntimeError: you must first build vocabulary before training the model
Processing zip files
{'/home/kaspar/ResearchDrive/1860-1869.zip', '/home/kaspar/ResearchDrive/1880-1889.zip', '/home/kaspar/ResearchDrive/1870-1879.zip', '/home/kaspar/ResearchDrive/1850-1859.zip'}
Process LokyProcess-1:
Traceback (most recent call last):
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py", line 418, in _process_worker
    r = call_item()
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py", line 272, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py", line 567, in __call__
    return self.func(*args, **kwargs)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/parallel.py", line 225, in __call__
    for func, args, kwargs in self.items]
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/parallel.py", line 225, in <listcomp>
    for func, args, kwargs in self.items]
  File "/home/kaspar/KB-RiR/Notebooks/ResearchCloud/utils_parallel.py", line 46, in read_doc
    BytesIO(zipdoc)
  File "src/lxml/etree.pyx", line 3467, in lxml.etree.parse
  File "src/lxml/parser.pxi", line 1856, in lxml.etree._parseDocument
  File "src/lxml/parser.pxi", line 1876, in lxml.etree._parseMemoryDocument
  File "src/lxml/parser.pxi", line 1764, in lxml.etree._parseDoc
  File "src/lxml/parser.pxi", line 1127, in lxml.etree._BaseParser._parseDoc
  File "src/lxml/parser.pxi", line 601, in lxml.etree._ParserContext._handleParseResultDoc
  File "src/lxml/parser.pxi", line 711, in lxml.etree._handleParseResult
  File "src/lxml/parser.pxi", line 640, in lxml.etree._raiseParseError
  File "<string>", line 1
lxml.etree.XMLSyntaxError: Start tag expected, '<' not found, line 1, column 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/kaspar/anaconda3/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/kaspar/anaconda3/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py", line 421, in _process_worker
    result_queue.put(_ResultItem(call_item.work_id, exception=exc))
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/backend/queues.py", line 234, in put
    obj = dumps(obj, reducers=self._reducers)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/backend/reduction.py", line 243, in dumps
    dump(obj, buf, reducers=reducers, protocol=protocol)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/backend/reduction.py", line 236, in dump
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/cloudpickle/cloudpickle.py", line 267, in dump
    return Pickler.dump(self, obj)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 662, in save_reduce
    save(state)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 859, in save_dict
    self._batch_setitems(obj.items())
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 885, in _batch_setitems
    save(v)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 662, in save_reduce
    save(state)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 859, in save_dict
    self._batch_setitems(obj.items())
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 885, in _batch_setitems
    save(v)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 524, in save
    rv = reduce(self.proto)
TypeError: can't pickle lxml.etree._ListErrorLog objects
Process LokyProcess-6:
Traceback (most recent call last):
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py", line 418, in _process_worker
    r = call_item()
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py", line 272, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py", line 567, in __call__
    return self.func(*args, **kwargs)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/parallel.py", line 225, in __call__
    for func, args, kwargs in self.items]
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/parallel.py", line 225, in <listcomp>
    for func, args, kwargs in self.items]
  File "/home/kaspar/KB-RiR/Notebooks/ResearchCloud/utils_parallel.py", line 46, in read_doc
    BytesIO(zipdoc)
  File "src/lxml/etree.pyx", line 3467, in lxml.etree.parse
  File "src/lxml/parser.pxi", line 1856, in lxml.etree._parseDocument
  File "src/lxml/parser.pxi", line 1876, in lxml.etree._parseMemoryDocument
  File "src/lxml/parser.pxi", line 1764, in lxml.etree._parseDoc
  File "src/lxml/parser.pxi", line 1127, in lxml.etree._BaseParser._parseDoc
  File "src/lxml/parser.pxi", line 601, in lxml.etree._ParserContext._handleParseResultDoc
  File "src/lxml/parser.pxi", line 711, in lxml.etree._handleParseResult
  File "src/lxml/parser.pxi", line 640, in lxml.etree._raiseParseError
  File "<string>", line 8
lxml.etree.XMLSyntaxError: Premature end of data in tag p line 8, line 8, column 453

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/kaspar/anaconda3/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/kaspar/anaconda3/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py", line 421, in _process_worker
    result_queue.put(_ResultItem(call_item.work_id, exception=exc))
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/backend/queues.py", line 234, in put
    obj = dumps(obj, reducers=self._reducers)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/backend/reduction.py", line 243, in dumps
    dump(obj, buf, reducers=reducers, protocol=protocol)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/backend/reduction.py", line 236, in dump
    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/cloudpickle/cloudpickle.py", line 267, in dump
    return Pickler.dump(self, obj)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 662, in save_reduce
    save(state)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 859, in save_dict
    self._batch_setitems(obj.items())
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 885, in _batch_setitems
    save(v)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 549, in save
    self.save_reduce(obj=obj, *rv)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 662, in save_reduce
    save(state)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 859, in save_dict
    self._batch_setitems(obj.items())
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 885, in _batch_setitems
    save(v)
  File "/home/kaspar/anaconda3/lib/python3.7/pickle.py", line 524, in save
    rv = reduce(self.proto)
TypeError: can't pickle lxml.etree._ListErrorLog objects
2019-11-25 18:19:44,302 : ERROR : exception calling callback for <Future at 0x7f755bfde7d0 state=finished raised TerminatedWorkerError>
Traceback (most recent call last):
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/_base.py", line 625, in _invoke_callbacks
    callback(self)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/parallel.py", line 309, in __call__
    self.parallel.dispatch_next()
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/parallel.py", line 731, in dispatch_next
    if not self.dispatch_one_batch(self._original_iterator):
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/parallel.py", line 759, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/parallel.py", line 716, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py", line 510, in apply_async
    future = self._workers.submit(SafeFunction(func))
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py", line 151, in submit
    fn, *args, **kwargs)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py", line 1022, in submit
    raise self._flags.broken
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {EXIT(1), EXIT(1)}
728315
Traceback (most recent call last):
  File "train_word2vec_azure.py", line 21, in <module>
    sentences.prepareLines()
  File "/home/kaspar/KB-RiR/Notebooks/ResearchCloud/utils_parallel.py", line 134, in prepareLines
    for s in self._processZip():
  File "/home/kaspar/KB-RiR/Notebooks/ResearchCloud/utils_parallel.py", line 102, in _processZip
    article_text = Parallel(n_jobs=self._n_jobs)(delayed(read_doc)(zipdoc,f) for (zipdoc,f) in article_text)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/parallel.py", line 934, in __call__
    self.retrieve()
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/parallel.py", line 833, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py", line 521, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/kaspar/anaconda3/lib/python3.7/concurrent/futures/_base.py", line 435, in result
    return self.__get_result()
  File "/home/kaspar/anaconda3/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/_base.py", line 625, in _invoke_callbacks
    callback(self)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/parallel.py", line 309, in __call__
    self.parallel.dispatch_next()
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/parallel.py", line 731, in dispatch_next
    if not self.dispatch_one_batch(self._original_iterator):
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/parallel.py", line 759, in dispatch_one_batch
    self._dispatch(tasks)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/parallel.py", line 716, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py", line 510, in apply_async
    future = self._workers.submit(SafeFunction(func))
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py", line 151, in submit
    fn, *args, **kwargs)
  File "/home/kaspar/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py", line 1022, in submit
    raise self._flags.broken
joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {EXIT(1), EXIT(1)}
