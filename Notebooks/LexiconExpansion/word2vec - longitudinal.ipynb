{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.spatial.distance import cosine\n",
    "from gensim.models import word2vec\n",
    "import seaborn as sns\n",
    "import random\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_year = lambda x: int(x.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1])\n",
    "average_vector = lambda words,model : np.mean([model.wv.__getitem__(w) for w in words if model.wv.__contains__(w)],axis=0)\n",
    "\n",
    "def sample(wordlist,cutoff=0.8):\n",
    "    if isinstance(cutoff,float):\n",
    "        co = int(len(wordlist)*cutoff)\n",
    "    elif isinstance(cutoff,int):\n",
    "        co = cutoff\n",
    "    random.shuffle(wordlist)\n",
    "    return wordlist[:co]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [(p,get_year(p)) for p in glob(\"data/simon/embeddings_DH2019_hengchen-ros-marjanen-2019-07-07 (1)/NL_diachronic/models/*.w2v\")]\n",
    "paths_filt = [t for t in paths if t[1] >=1800]\n",
    "paths_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {y:word2vec.Word2Vec.load(p) for p,y in paths_filt}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect neighbouring words across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed = [\"vrouw\",\"vrouwe\",\"vrouwen\"]\n",
    "#seed = [\"moeder\",\"moeders\"]\n",
    "#seed = ['man','mannen']\n",
    "#seed = ['vader','vaders']\n",
    "#seed = ['mensch','menschen','mensen']\n",
    "seed = ['zacht','bedaard','teeder','geduldig','kalm','zwak','liefelijk','goedig','zagt','zachtkens','goedig',\"arme\"]\n",
    "#seed = ['vrouw','vrouwen','moeder','moeders']\n",
    "#seed = ['man','mannen','mau','heer',\"vader\",\"vaders\",'grootvader','schoonvader','broeder','zoon']\n",
    "#seed = [\"levendig\",\"gelukkig\",\"welvarend\"]\n",
    "seed = [\"huis\",\"huys\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbours(seed):\n",
    "    neighbours = [] \n",
    "    \n",
    "    for year in sorted(models.keys()):\n",
    "        av_vector = average_vector(seed,models[year])\n",
    "        neighbours.extend([w for w,v in models[year].wv.similar_by_vector(av_vector,topn=50)])\n",
    "    \n",
    "    return Counter(neighbours)\n",
    "\n",
    "ns = get_neighbours(seed)\n",
    "ns.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_fem = []\n",
    "sims_male = []\n",
    "fem_pole = [\"vrouw\",'viouw','vronw','vrouwen']\n",
    "#fem_target = ['mensch','menschen','mensen','wezens','menseh','mensehen','menseben']\n",
    "#fem_target = ['moeder','moeders','grootmoeder','schoonmoeder']\n",
    "#fem_target = ['kind','kinderen','kindertjes','kinders','kindereu','dochters','zuigeling']\n",
    "fem_target = ['zacht','bedaard','teeder','geduldig','kalm','zwak','liefelijk','goedig','zagt','zachtkens','goedig']\n",
    "#fem_target = ['werktuig','machine','machines','stoommachine','stoomwerktuig']\n",
    "male_pole = ['man','mannen','mau']\n",
    "#male_target = ['kind','kinderen','kindertjes','kinders','kindereu','dochters','zuigeling']\n",
    "#male_target = ['mensch','menschen','mensen','wezens','menseh','mensehen','menseben']\n",
    "#male_target = ['grootvader','vader','vaders','schoonvader',\"huisvader\"]\n",
    "#male_taget = ['werktuig','machine','machines','stoommachine','stoomwerktuig']\n",
    "male_target = ['zacht','bedaard','teeder','geduldig','kalm','zwak','liefelijk','goedig','zagt','zachtkens','goedig']\n",
    "\n",
    "\n",
    "for year in sorted(models.keys()):\n",
    "    model = models[year]\n",
    "    sims_fem.append(1- cosine(average_vector(fem_pole,model),average_vector(fem_target,model)))\n",
    "    sims_male.append(1- cosine(average_vector(male_pole,model),average_vector(male_target,model)))\n",
    "    \n",
    "df = pd.DataFrame(np.array([sims_fem,sims_male]).T,columns=[\"female\",'male'],index=sorted(models.keys()))\n",
    "df['bias'] = df[\"female\"] - df['male']\n",
    "df['bias'].plot(ylim=(-1.0,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"female\",'male']].plot(kind='bar',alpha=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive Lexicon Expansion\n",
    "### Bootstrapped SemAxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "\n",
    "\n",
    "def sort_scores(scores,topn=-1,ascending=False):\n",
    "    return sorted(scores.items(),key = lambda x: x[1],reverse=not ascending)[:topn]\n",
    "\n",
    "def top_new(sorted_vocab,seen,topn=10):\n",
    "    i = 0\n",
    "    candidates = []\n",
    "    while len(candidates) < topn:\n",
    "        if sorted_vocab[i][0] not in seen:\n",
    "            candidates.append(sorted_vocab[i][0])\n",
    "        i+=1  \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topn_new(neighbours,seen,topn=10):\n",
    "    neighbours = sorted(neighbours.items(),key=lambda x: x[1], reverse=True)\n",
    "    c = 0\n",
    "    candidates = []\n",
    "    while len(candidates) < topn and c < len(neighbours):\n",
    "        if neighbours[c][0] not in seen:\n",
    "            candidates.append(neighbours[c])\n",
    "        c+=1\n",
    "    return dict(candidates)  \n",
    "\n",
    "\n",
    "def lex_exp_bootstrap(core,model,pole=None,seen=None,stop_at=20,cutoff=5):\n",
    "    \n",
    "    if not seen:\n",
    "        seen = core.copy()\n",
    "    if not pole:\n",
    "        pole = core.copy()\n",
    "    rounds = 0\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            #clear_output(wait=True)\n",
    "            print(\"{} words selected.\".format(len(core)))\n",
    "            #print(\"words retained :\"+ ' '.join(pole))\n",
    "            neighbours = defaultdict(float)\n",
    "            #for year,model in models.items():\n",
    "            for _ in range(5):\n",
    "                for w,v in model.wv.similar_by_vector(average_vector(sample(list(core),cutoff),model),topn=100):\n",
    "                    neighbours[w]+=v\n",
    "            \n",
    "            neighbours = topn_new(neighbours,seen)\n",
    "            \n",
    "            max_val = np.max(list(neighbours.values()))\n",
    "            neighbours = {w:v/max_val for w,v in neighbours.items()}\n",
    "            annotations = [(w,int(input(f'Target word=\"{w}\"; value=\"{round(v,2)}\"\\n(Options: core = 1; keep = 2; no = 0)'))) \n",
    "                                   for w,v in sorted(neighbours.items(),key=lambda x: x[1])]\n",
    "            core.update([w for w,a in annotations if a==1])\n",
    "            pole.update([w for w,a in annotations if a])\n",
    "            seen.update([w for w,a in annotations])\n",
    "            rounds+=1\n",
    "            \n",
    "            if len(core) > stop_at:\n",
    "                return core,pole,seen\n",
    "            \n",
    "        except (KeyboardInterrupt,TypeError) as e:\n",
    "            print(f'Leaving because {e}')\n",
    "            print(f\"Leaving after {rounds} annotation rounds.\")\n",
    "            return core,pole,seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pole = {\"man\",'mannen',\"heer\",\"heeren\",\"heren\",'mijnheer',\"zoon\",\"vader\"}\n",
    "core = {\"moeder\",\"vrouw\",\"dochter\",\"dogter\",\"vrouwen\",\"moeders\",\"grootmoeders\",\"meid\"}\n",
    "\n",
    "def longitudinal_expansion(core,models):\n",
    "    logging = defaultdict(dict)\n",
    "    pole = set()\n",
    "    seen = set()\n",
    "    rounds = 0\n",
    "    stop_at = 10\n",
    "    while True:\n",
    "        try:\n",
    "            for year, model in sorted(models.items()):\n",
    "                print(f\"At {year}-{rounds}\")\n",
    "                print(stop_at)\n",
    "                #core = {w for w in core if model.wv.__contains__(w)}\n",
    "                core,pole,seen = lex_exp_bootstrap(core,model,pole=pole,seen=seen,stop_at=stop_at)\n",
    "                stop_at = (len(core) + 10)\n",
    "                logging[rounds][year] = (core,pole,seen)\n",
    "            rounds+=1\n",
    "        \n",
    "        except (KeyboardInterrupt,TypeError) as e:\n",
    "            print(f'Leaving because {e}')\n",
    "            print(f\"Leaving after {rounds} annotation rounds.\")\n",
    "            return logging\n",
    "\n",
    "logging = longitudinal_expansion(core,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lex_exp_semaxis(pole_1,pole_2,model,topn=10):\n",
    "    def create_axis(pole1,pole2):\n",
    "        v1 = np.mean([model.wv[w] for w in pole1 if w in model.wv.vocab],axis=0)\n",
    "        v2 = np.mean([model.wv[w] for w in pole2 if w in model.wv.vocab],axis=0)\n",
    "        return v1 - v2\n",
    "\n",
    "    def sort_vocab_by_axis(axis,model=model):\n",
    "        def project_word(w):\n",
    "            return 1 - cosine(model.wv[w],axis)\n",
    "        return {w : project_word(w) for w in tqdm_notebook(model.wv.vocab)}\n",
    "    \n",
    "    seen = set(pole_1).union(pole_2)\n",
    "    rounds = 0\n",
    "    \n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            clear_output(wait=True)\n",
    "            rounds+=1\n",
    "            \n",
    "            print(f\"Pole 1 Lexicon (r.{rounds}): \" + ' '.join(pole_1))\n",
    "            print(f\"Pole 2 Lexicon (r.{rounds}): \" + ' '.join(pole_2))\n",
    "            axis = create_axis(pole_1,pole_2)\n",
    "            sorted_vocab = sort_scores(sort_vocab_by_axis(axis))\n",
    "            for sort_dir in [1,-1]:\n",
    "                print(\"\\n\")\n",
    "                candidates = [w for w in top_new(sorted_vocab[::sort_dir],seen,topn=topn)]\n",
    "                annotations = [(w,int(input(f'Target word=\"{w}\"\\n(Options: pole_1 = 1,pole_2 = 2, na = 0)'))) for w in candidates]\n",
    "                pole_1.update([w for w,i in annotations if i==1]);pole_2.update([w for w,i in annotations if i==2])\n",
    "                seen.update(candidates)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"Leaving after {rounds} annotation rounds.\")\n",
    "            return pole_1,pole_2\n",
    "        \n",
    "#pole_1 = {\"vrouw\",\"vrouwen\",\"moeder\",\"moeders\"}\n",
    "#pole_2 = {\"man\",\"mannen\",\"vader\",\"vaders\"}\n",
    "pole_1 = {'roomschkatholieke','roomsch','roomsch-katholieke','katholieke'}\n",
    "pole_2 = {'gereformeerde','luthersche','nederlandsch-hervormde','baptisten'}\n",
    "\n",
    "p1,p2 = lex_exp_semaxis(pole_1,pole_2,models[1880])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pole_1 = {\"vrouw\",\"vrouwen\"}\n",
    "pole_2 = {\"man\",\"mannen\"}\n",
    "pole_1.union(pole_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = defaultdict(list) \n",
    "pole_1 = [\"Maria\", \"Johanna\", \"Anna\", \"Cornelia\", \"Adriana\", \"Wilhelmina\", \"Catharina\", \"Hendrika\", \"Elisabeth\", \"Grietje\", \"Aaltje\", \"Jantje\", \"Trijntje\", \"Petronella\", \"Jacoba\",\"Geertruida\", \"Geertje\", \"Janna\", \"Elizabeth\", \"Neeltje\", \"Helena\", \"Antje\", \"Margaretha\", \"Jannetje\", \"Hendrikje\"]\n",
    "pole_1 = [w.lower() for w in pole_1]\n",
    "pole_2 = [\"Jan\", \"Johannes\", \"Hendrik\", \"Cornelis\", \"Willem\", \"Pieter\", \"Gerrit\", \"Jacob\",\"Jacobus\", \"Petrus\"\t, \"Adrianus\", \"Dirk\", \"Hendrikus\", \"Wilhelmus\", \"Gerardus\", \"Klaas\", \"Marinus\", \"Antonius\",\"Albert\", \"Johan\", \"Adriaan\", \"Peter\", \"Harm\", \"Theodorus\"]\n",
    "pole_2 = [w.lower() for w in pole_2]\n",
    "pole_1 += [\"vrouw\",'viouw','vronw','vrouwen',\"mevrouw\",\"moeder\",\"moeders\",'grootmoeder','egtgenoote','zufter',\"dochter\",\"schoonmoeder\",\"juffer\",\"nicht\"]\n",
    "pole_2 += ['man','mannen','mau','heer',\"vader\",\"vaders\",'grootvader','schoonvader','broeder','zoon',\"broeder\",\"oom\",\"neef\"]\n",
    "#target = ['zacht','bedaard','teeder','geduldig','kalm','zwak','liefelijk','goedig','zagt','zachtkens','goedig','arme']\n",
    "#target =  [\"machine\",'werktuig','werktuigen','machines','vervaardigen','werkte','werk','werkjen']\n",
    "target = ['kind','kinderen','kindertjes','kinders','kindereu','dochters','zuigeling']\n",
    "#target =  ['mensch','menschen','mensen','wezens','menseh','mensehen','menseben','mens']\n",
    "#pole_1 = ['katholieke', 'roomsch', 'klerikale', 'clericale', 'roomschkatholieke', 'ultramontaansche', 'roomsch-katholieke']\n",
    "#pole_2 = ['lutb', 'horvormdo', 'lnth', 'luthersche', 'gereformeerde', 'hervormdo', 'gertf', 'doopsgezinde', 'luth', 'horv', 'evang', 'bapti']\n",
    "#target = [\"nederlandsen\",\"nederlandsch\",\"nederland\",\"vaderlandsch\",\"vaderland\"]\n",
    "\n",
    "\n",
    "\n",
    "for year,model in tqdm_notebook(sorted(models.items())):\n",
    "    for _ in range(100):\n",
    "        p1 = 1 - cosine(average_vector(sample(pole_1),model),average_vector(sample(target),model))\n",
    "        p2 = 1- cosine(average_vector(sample(pole_2),model),average_vector(sample(target),model))\n",
    "        bias[year].append(p1-p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array([[np.mean(v),np.std(v)] for k,v in bias.items()]),columns=['mean','std'],index=sorted(models.keys()))\n",
    "df['mean'].plot(kind=\"bar\",yerr=df['std'],align='center',  alpha=0.5, ecolor='black', capsize=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
